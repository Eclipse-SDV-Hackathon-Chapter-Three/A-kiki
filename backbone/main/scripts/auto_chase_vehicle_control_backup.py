#!/usr/bin/env python3
"""
Auto Chase Vehicle Control Script
ì¶©ëŒ ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ ì¶”ê²©í•˜ëŠ” ì°¨ëŸ‰ ì œì–´ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import carla
import numpy as np
import cv2
import threading
import time
import pygame
import json
import base64
import signal
import atexit

# Zenoh imports
try:
    import zenoh
    ZENOH_AVAILABLE = True
except ImportError:
    ZENOH_AVAILABLE = False
    print("Warning: zenoh not available, control commands will not be published")

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆë“¤ì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from chase.perception.bounding_box_detector import BoundingBoxDetector
from chase.perception.collision_detector import CollisionDetector
from chase.perception.collision_vehicle_tracker import CollisionVehicleTracker
from chase.planning.simple_chase_planner import SimpleChasePlanner
# from chase.control.vehicle_controller import ChaseVehicleController  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
from vehicle.optimized_camera_view import OptimizedCameraView

# ì „ì—­ ë³€ìˆ˜ (ì •ë¦¬ìš©)
_auto_chase_instance = None

def cleanup_opencv_windows():
    """OpenCV ìœˆë„ìš° ì •ë¦¬ í•¨ìˆ˜"""
    try:
        print("ğŸ§¹ Cleaning up OpenCV windows...")
        cv2.destroyAllWindows()
        cv2.waitKey(1)
        print("âœ… OpenCV windows cleaned up")
    except Exception as e:
        print(f"âš ï¸ Error cleaning OpenCV windows: {e}")

def signal_handler(signum, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (Ctrl+C ë“±)"""
    print(f"\nğŸ›‘ Received signal {signum}, cleaning up...")
    cleanup_opencv_windows()
    if _auto_chase_instance:
        _auto_chase_instance.cleanup()
    sys.exit(0)

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# atexit í•¸ë“¤ëŸ¬ ë“±ë¡
atexit.register(cleanup_opencv_windows)

class AutoChaseVehicleControl:
    """ìë™ ì¶”ê²© ì°¨ëŸ‰ ì œì–´ í´ë˜ìŠ¤"""
    
    def __init__(self):
        global _auto_chase_instance
        _auto_chase_instance = self
        
        self.client = None
        self.world = None
        self.vehicle = None
        
        # ëª¨ë“ˆë“¤
        self.bounding_box_detector = None
        self.collision_detector = None
        self.vehicle_tracker = None
        self.chase_planner = None
        # self.vehicle_controller = None  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        
        # ì¹´ë©”ë¼ ë·°
        self.camera_view = None
        
        # ì œì–´ ìƒíƒœ
        self.running = True
        self.is_chasing = False
        self.last_update_time = 0.0
        self.update_interval = 0.05  # 50ms ì—…ë°ì´íŠ¸ ê°„ê²© (ë” ë¹ ë¥¸ ë°˜ì‘)
        
        # IMU ì„¼ì„œ
        self.imu_sensor = None
        self.current_imu_data = None
        
        # Zenoh for control commands
        self.zenoh_session = None
        self.target_vehicle_id = None  # Target vehicle ID to control
        self.zenoh_subscribers = []
        self.zenoh_camera_image = None  # Latest camera image from Zenoh
        self.zenoh_detected_objects = []  # Latest detected objects from Zenoh
        self.use_zenoh_camera_only = False  # Use only Zenoh camera data
        
        # í†µê³„
        self.chase_statistics = {
            'total_detections': 0,
            'collision_events': 0,
            'tracking_duration': 0.0,
            'chase_distance': 0.0,
            'max_speed_reached': 0.0
        }
        
        # print("ğŸš” Auto Chase Vehicle Control initialized")
    
    def connect_to_carla(self, host='localhost', port=2000):
        """CARLA ì„œë²„ì— ì—°ê²°"""
        try:
            self.client = carla.Client(host, port)
            self.client.set_timeout(10.0)
            self.world = self.client.get_world()
            
            # print(f"âœ… Connected to CARLA server at {host}:{port}")
            return True
            
        except Exception as e:
            # print(f"âŒ Failed to connect to CARLA: {e}")
            return False
    
    def setup_zenoh(self):
        """Setup Zenoh connection for publishing control commands"""
        try:
            if not ZENOH_AVAILABLE:
                # print("âš ï¸ Zenoh not available, skipping Zenoh setup")
                return False

            # Initialize Zenoh session
            zenoh_config = zenoh.Config()
            try:
                zenoh_config.insert_json5("connect/endpoints", '["tcp/127.0.0.1:7447"]')
                zenoh_config.insert_json5("transport/shared_memory/enabled", "true")
                # print("ğŸš€ Connecting to SHM-enabled Zenoh router...")
            except Exception:
                print("ğŸ“¡ Using peer-to-peer Zenoh connection...")

            self.zenoh_session = zenoh.open(zenoh_config)
            # print("âœ… Connected to Zenoh router successfully")
            
            # Subscribe to vehicle telemetry from CARLA spawner
            telemetry_subscriber = self.zenoh_session.declare_subscriber(
                "carla/vehicle/telemetry", self.on_vehicle_id_received
            )
            self.zenoh_subscribers.append(telemetry_subscriber)
            # print("ğŸ“¡ Subscribed to vehicle telemetry for target vehicle ID")
            
            # Subscribe to camera images from CARLA spawner
            camera_subscriber = self.zenoh_session.declare_subscriber(
                "carla/vehicle/camera", self.on_camera_image_received
            )
            self.zenoh_subscribers.append(camera_subscriber)
            # print("ğŸ“· Subscribed to camera images for collision detection")
            
            return True

        except Exception as e:
            # print(f"âŒ Failed to setup Zenoh: {e}")
            self.zenoh_session = None
            return False
    
    def on_vehicle_id_received(self, sample):
        """Handle received vehicle ID from CARLA spawner (Zero-copy)"""
        try:
            # print(f"ğŸ“¡ Received telemetry data, payload type: {type(sample.payload)}")
            # print(f"ğŸ“¡ Payload size: {len(sample.payload)} bytes")
            
            # Zero-copy: Use ZBytes to_string() method
            if hasattr(sample.payload, 'to_string'):
                # Use ZBytes to_string() method (zero-copy)
                payload_str = sample.payload.to_string()
                # print(f"ğŸ“¡ Got string from ZBytes: {len(payload_str)} chars")
            elif hasattr(sample.payload, 'to_bytes'):
                # Fallback: use to_bytes() then decode
                payload_str = sample.payload.to_bytes().decode('utf-8')
            else:
                # Final fallback
                payload_str = sample.payload.decode('utf-8')
            
            # Parse JSON (minimal overhead)
            telemetry_data = json.loads(payload_str)
            # print(f"ğŸ“¡ Telemetry data keys: {list(telemetry_data.keys())}")
            
            # Extract vehicle ID from telemetry
            if not self.target_vehicle_id:
                # Try to get vehicle ID from telemetry data
                if 'vehicle_id' in telemetry_data:
                    self.target_vehicle_id = telemetry_data['vehicle_id']
                elif 'id' in telemetry_data:
                    self.target_vehicle_id = telemetry_data['id']
                else:
                    # Default fallback
                    self.target_vehicle_id = 137
                
                # print(f"ğŸ¯ Target vehicle ID set to: {self.target_vehicle_id}")
            
        except Exception as e:
            print(f"âš ï¸ Error processing vehicle ID: {e}")
            # print(f"âš ï¸ Payload type: {type(sample.payload)}")
            ##Don't print full payload to avoid spam
    
    def on_camera_image_received(self, sample):
        """Handle received camera image from CARLA spawner via Zenoh (Zero-copy)"""
        try:
            # print(f"ğŸ“· Received camera data, payload type: {type(sample.payload)}")
            # print(f"ğŸ“· Payload size: {len(sample.payload)} bytes")
            
            # Zero-copy: Use ZBytes to_bytes() method
            # 247KB suggests JPEG compressed image data
            if hasattr(sample.payload, 'to_bytes'):
                # Use ZBytes to_bytes() method (zero-copy)
                image_bytes = sample.payload.to_bytes()
                # print(f"ğŸ“· Got bytes from ZBytes: {len(image_bytes)} bytes")
                
                # Try to decode as JPEG/PNG first (most likely for 247KB)
                image = cv2.imdecode(np.frombuffer(image_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)
                
                if image is not None:
                    # pass
                    print(f"ğŸ“· Decoded compressed image: {image.shape}")
                else:
                    # If JPEG/PNG fails, try raw image formats
                    array = np.frombuffer(image_bytes, dtype=np.uint8)
                    # print(f"ğŸ“· Trying raw image decode from {len(array)} bytes")
                    
                    # Try common image dimensions for raw data
                    possible_shapes = [
                        (480, 640, 3),   # 480p RGB (921,600 bytes)
                        (720, 1280, 3),  # 720p RGB (2,764,800 bytes)
                        (900, 1600, 3),  # 900p RGB (4,320,000 bytes)
                        (1080, 1920, 3), # 1080p RGB (6,220,800 bytes)
                    ]
                    
                    for height, width, channels in possible_shapes:
                        expected_size = height * width * channels
                        if len(array) == expected_size:
                            image = array.reshape((height, width, channels))
                            # print(f"ğŸ“· Raw image decoded: {height}x{width}x{channels}")
                            break
            else:
                # print("âš ï¸ ZBytes does not have to_bytes() method")
                return
            
            if image is not None:
                # Store reference (zero-copy)
                self.zenoh_camera_image = image
                # print(f"ğŸ“· Stored camera image: {image.shape}")
                
                # Process image for collision detection
                self.process_zenoh_camera_image(image)
            else:
                # print("âš ï¸ Failed to interpret image data")
                # print(f"âš ï¸ Array size: {len(array)} bytes")
                pass
        except Exception as e:
            # print(f"âš ï¸ Error processing camera image: {e}")
            # print(f"âš ï¸ Payload type: {type(sample.payload)}")
            # print(f"âš ï¸ Payload attributes: {dir(sample.payload)}")
            pass
    
    def process_zenoh_camera_image(self, image):
        """Process camera image from Zenoh for collision detection"""
        try:
            # print(f"ğŸ” Processing Zenoh camera image: {image.shape if image is not None else 'None'}")
            
            # Use OpenCV-based object detection
            detected_objects = self.detect_objects_opencv(image)
            
            # Store detected objects for display
            self.zenoh_detected_objects = detected_objects
            
            # print(f"ğŸ¯ OpenCV detected {len(detected_objects)} objects from Zenoh camera")
            
            if detected_objects:
                # ê°ì²´ ì •ë³´ ì¶œë ¥
                # for i, obj in enumerate(detected_objects):
                    # print(f"  Object {i}: ID={obj.get('actor_id', 'Unknown')}, bbox={obj.get('bbox_2d', [])}")
                
                # ê°œì„ ëœ ì¶©ëŒ ê°ì§€ (ê±°ë¦¬ì™€ í¬ê¸° ê¸°ë°˜)
                collision_detected = False
                collision_objects = []
                
                for obj in detected_objects:
                    bbox = obj.get('bbox_2d', [])
                    distance = obj.get('distance_estimate', 100)
                    
                    if len(bbox) >= 4:
                        x, y, w, h = bbox[:4]
                        area = w * h
                        
                        # ì‚¬ëŒ-ì°¨ëŸ‰ ì¶©ëŒ ê°ì§€ ì¡°ê±´ (ì¹´ë©”ë¼ ê¸°ë°˜)
                        # 1. ê±°ë¦¬ê°€ 30m ì´ë‚´ (ì¶©ëŒ ìœ„í—˜ êµ¬ì—­)
                        # 2. ì¶©ë¶„íˆ í° ê°ì²´ (ì‚¬ëŒ + ì°¨ëŸ‰ ì¡°í•©)
                        # 3. í™”ë©´ ì¤‘ì•™ì— ìœ„ì¹˜í•œ ê°ì²´
                        # 4. íŠ¹ì • í¬ê¸° ë²”ìœ„ì˜ ê°ì²´ (ì‚¬ëŒê³¼ ì°¨ëŸ‰ì´ í•¨ê»˜ ë³´ì´ëŠ” ê²½ìš°)
                        
                        aspect_ratio = w / h if h > 0 else 1.0
                        is_close = distance <= 30  # ì¶©ëŒ ìœ„í—˜ ê±°ë¦¬ë¡œ ë‹¨ì¶•
                        is_large = area > 20000   # ì‚¬ëŒ+ì°¨ëŸ‰ ì¡°í•© í¬ê¸°
                        is_center_large = (area > 12000 and 
                                         abs(x + w/2 - image.shape[1]/2) < image.shape[1]/4)  # í™”ë©´ ì¤‘ì•™
                        
                        # ì‚¬ëŒ-ì°¨ëŸ‰ ì¶©ëŒ íŠ¹ì„±:
                        # 1. ê°€ë¡œë¡œ ê¸´ ê°ì²´ (ì°¨ëŸ‰ì´ ì‚¬ëŒì„ ì¹˜ê³  ì§€ë‚˜ê°€ëŠ” ê²½ìš°)
                        is_horizontal_collision = (aspect_ratio > 1.8 and area > 15000)
                        
                        # 2. ì„¸ë¡œë¡œ ê¸´ ê°ì²´ (ì°¨ëŸ‰ì´ ì‚¬ëŒì„ ì •ë©´ì—ì„œ ì¹˜ëŠ” ê²½ìš°)
                        is_vertical_collision = (aspect_ratio < 0.6 and area > 18000)
                        
                        # 3. ì¤‘ê°„ í¬ê¸°ì˜ ë¶ˆê·œì¹™í•œ ê°ì²´ (ì‚¬ëŒê³¼ ì°¨ëŸ‰ì´ ê²¹ì³ ë³´ì´ëŠ” ê²½ìš°)
                        is_irregular_collision = (0.7 < aspect_ratio < 1.3 and 10000 < area < 25000)
                        
                        # 4. ë§¤ìš° ê°€ê¹Œìš´ ê±°ë¦¬ì˜ í° ê°ì²´ (ì§ì ‘ ì¶©ëŒ)
                        is_direct_collision = (distance <= 15 and area > 15000)
                        
                        if (is_close or is_large or is_center_large or 
                            is_horizontal_collision or is_vertical_collision or 
                            is_irregular_collision or is_direct_collision):
                            collision_detected = True
                            collision_objects.append(obj)
                            # print(f"ğŸš¨ COLLISION detected for object {obj.get('actor_id', 'Unknown')}: "
                            #       f"size={w}x{h}, area={area}, distance={distance}m, aspect={aspect_ratio:.2f}, "
                            #       f"close={is_close}, large={is_large}, center={is_center_large}, "
                            #       f"horizontal={is_horizontal_vehicle}, vertical={is_vertical_vehicle}")
                
                if collision_detected:
                    # print(f"ğŸš¨ COLLISION DETECTED from Zenoh camera: {len(collision_objects)} collision objects")
                    self.chase_statistics['collision_events'] += len(collision_objects)
                    
                    # ì¦‰ì‹œ ì¶”ê²© ì‹œì‘
                    # print("ğŸš” Starting immediate chase from collision detection")
                    self.is_chasing = True
                    
                    # ì¶©ëŒ ê°ì²´ë“¤ì„ collision_detectedë¡œ ë§ˆí‚¹
                    for obj in collision_objects:
                        obj['collision_detected'] = True
                    
                else:
                    pass
                    # print("âœ… No collision detected - no qualifying objects found")
            
        except Exception as e:
            # print(f"âš ï¸ Error processing Zenoh camera image: {e}")
            import traceback
            traceback.print_exc()
    
    def detect_objects_opencv(self, image):
        """Detect objects using OpenCV - focused on person-vehicle collision detection"""
        try:
            # print(f"ğŸ” Detecting objects in camera view: {image.shape}")
            
            # Enhanced object detection for person-vehicle collision
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Apply Gaussian blur for better edge detection
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # Edge detection with adjusted parameters for person-vehicle detection
            edges = cv2.Canny(blurred, 30, 100)  # Lower thresholds for better detection
            
            # Morphological operations to connect nearby edges
            kernel = np.ones((3,3), np.uint8)
            edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # Find contours
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detected_objects = []
            height, width = image.shape[:2]
            
            for i, contour in enumerate(contours):
                # Filter by area - adjusted for person-vehicle detection
                area = cv2.contourArea(contour)
                if area > 300:  # Lower threshold for person detection
                    # Get bounding box
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # Only include objects that are significantly within camera view
                    margin = 30  # Reduced margin for better detection
                    if (x > margin and y > margin and 
                        x + w < width - margin and y + h < height - margin):
                        
                        # Enhanced size check for person-vehicle collision
                        aspect_ratio = w / h if h > 0 else 1.0
                        
                        # Person-vehicle collision characteristics:
                        # 1. Person-like objects: taller than wide (aspect_ratio < 1.0)
                        # 2. Vehicle-like objects: wider than tall (aspect_ratio > 1.0)
                        # 3. Combined objects: mixed characteristics
                        
                        is_person_like = (aspect_ratio < 0.8 and 30 < w < 100 and 50 < h < 200)
                        is_vehicle_like = (aspect_ratio > 1.2 and 80 < w < 300 and 40 < h < 150)
                        is_combined_like = (0.8 <= aspect_ratio <= 1.2 and 60 < w < 200 and 60 < h < 180)
                        
                        if is_person_like or is_vehicle_like or is_combined_like:
                            # Determine object type based on characteristics
                            if is_person_like:
                                object_type = 'person'
                                confidence = min(0.9, area / 8000.0)
                            elif is_vehicle_like:
                                object_type = 'vehicle'
                                confidence = min(0.9, area / 12000.0)
                            else:
                                object_type = 'person_vehicle'  # Possible collision
                                confidence = min(0.9, area / 10000.0)
                            
                            # Create object data
                            obj = {
                                'actor_id': f'collision_object_{i}',
                                'bbox_2d': [x, y, w, h],
                                'world_location': [x, y, 0],
                                'object_type': object_type,
                                'confidence': confidence,
                                'in_camera_view': True,
                                'distance_estimate': self._estimate_distance_from_bbox(w, h),
                                'aspect_ratio': aspect_ratio,
                                'collision_risk': 'high' if object_type == 'person_vehicle' else 'medium'
                            }
                            detected_objects.append(obj)
                            # print(f"ğŸ¯ Detected {object_type} {i}: bbox=({x},{y},{w},{h}), area={area}, aspect={aspect_ratio:.2f}")
            
            # print(f"âœ… Total collision-related objects detected: {len(detected_objects)}")
            return detected_objects
            
        except Exception as e:
            print(f"âš ï¸ Error in OpenCV object detection: {e}")
            return []
    
    def _estimate_distance_from_bbox(self, width, height):
        """Estimate distance from bounding box size - optimized for person-vehicle collision detection"""
        # Distance estimation based on person-vehicle collision scenarios
        area = width * height
        aspect_ratio = width / height if height > 0 else 1.0
        
        # Person-like objects (taller than wide)
        if aspect_ratio < 0.8:
            if area > 15000:
                return 15  # Very close person
            elif area > 8000:
                return 25  # Close person
            elif area > 4000:
                return 40  # Medium distance person
            else:
                return 60  # Far person
        
        # Vehicle-like objects (wider than tall)
        elif aspect_ratio > 1.2:
            if area > 30000:
                return 20  # Very close vehicle
            elif area > 15000:
                return 35  # Close vehicle
            elif area > 8000:
                return 50  # Medium distance vehicle
            else:
                return 70  # Far vehicle
        
        # Combined or irregular objects (possible collision scenario)
        else:
            if area > 25000:
                return 12  # Very close collision scenario
            elif area > 12000:
                return 20  # Close collision scenario
            elif area > 6000:
                return 35  # Medium distance collision scenario
            else:
                return 55  # Far collision scenario
    
    
    def handle_zenoh_chase_control(self):
        """Handle chase control based on Zenoh camera data"""
        try:
            # print(f"ğŸš” Zenoh chase control: {len(self.zenoh_detected_objects)} objects")
            # print(f"ğŸš” Chase status: is_chasing={self.is_chasing}, collisions={self.chase_statistics['collision_events']}")
            
            # ì¶©ëŒ ì´ë²¤íŠ¸ê°€ ìˆê³  ì•„ì§ ì¶”ê²©ì„ ì‹œì‘í•˜ì§€ ì•Šì€ ê²½ìš°
            if self.chase_statistics['collision_events'] > 0 and not self.is_chasing:
                # print("ğŸš¨ Collision detected - starting chase from Zenoh data")
                
                # ê°€ì¥ í° ê°ì²´ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ì„ íƒ
                if self.zenoh_detected_objects:
                    target_obj = max(self.zenoh_detected_objects, 
                                   key=lambda x: x['bbox_2d'][2] * x['bbox_2d'][3])
                    
                    # print(f"ğŸ¯ Target selected: {target_obj['actor_id']}")
                    # print(f"ğŸ¯ Target bbox: {target_obj['bbox_2d']}")
                    
                    # ì¶”ê²© ì‹œì‘
                    self.is_chasing = True
                    # print("ğŸš” Chase started - is_chasing set to True")
                    
                    # ê°„ë‹¨í•œ ì¶”ê²© ì œì–´ ëª…ë ¹ ìƒì„±
                    self.apply_simple_chase_control(target_obj)
                else:
                    # print("âš ï¸ No detected objects for chase target")
                    pass
            
            # ì´ë¯¸ ì¶”ê²© ì¤‘ì¸ ê²½ìš° ì œì–´ ì—…ë°ì´íŠ¸
            elif self.is_chasing and self.zenoh_detected_objects:
                # print("ğŸš” Chase in progress - updating control")
                
                # ê°€ì¥ í° ê°ì²´ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ìœ ì§€
                target_obj = max(self.zenoh_detected_objects, 
                               key=lambda x: x['bbox_2d'][2] * x['bbox_2d'][3])
                
                print(f"ğŸ¯ Updating target: {target_obj['actor_id']}")
                self.apply_simple_chase_control(target_obj)
            
            elif self.is_chasing and not self.zenoh_detected_objects:
                print("âš ï¸ Chase active but no objects detected - stopping")
                self.is_chasing = False
            
            # ì¶”ê°€: ì¹´ë©”ë¼ í™”ë©´ ë‚´ í° ê°ì²´ ê°ì§€ ì‹œ ì¶”ê²© ì‹œì‘
            elif not self.is_chasing and self.zenoh_detected_objects:
                # ì¹´ë©”ë¼ í™”ë©´ì— ì¡íŒ ê°ì²´ ì¤‘ ê°€ì¥ í° ê²ƒì„ ì„ íƒ
                camera_objects = [obj for obj in self.zenoh_detected_objects 
                                if obj.get('in_camera_view', False)]
                
                if camera_objects:
                    largest_obj = max(camera_objects, 
                                    key=lambda x: x['bbox_2d'][2] * x['bbox_2d'][3])
                    bbox = largest_obj.get('bbox_2d', [])
                    distance = largest_obj.get('distance_estimate', 100)
                    
                    if len(bbox) >= 4:
                        w, h = bbox[2], bbox[3]
                        area = w * h
                        
                        # ì¹´ë©”ë¼ í™”ë©´ì— ì¡íŒ ì‚¬ëŒ-ì°¨ëŸ‰ ì¶©ëŒ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ê°ì²´
                        # ì‚¬ëŒê³¼ ì°¨ëŸ‰ì´ í•¨ê»˜ ë³´ì´ëŠ” ê²½ìš°ë¥¼ ê³ ë ¤í•œ ì¡°ê±´
                        if area > 8000 and distance <= 50:  # ì‚¬ëŒ-ì°¨ëŸ‰ ì¶©ëŒ ê°ì§€ ê±°ë¦¬
                            # print(f"ğŸ¯ Large camera object detected ({w}x{h}, {distance}m) - starting chase")
                            self.is_chasing = True
                            self.chase_statistics['collision_events'] += 1
                            self.apply_simple_chase_control(largest_obj)
                
        except Exception as e:
            print(f"âš ï¸ Error in Zenoh chase control: {e}")
            import traceback
            traceback.print_exc()
    
    def apply_simple_chase_control(self, target_obj):
        """Apply improved chase control based on target object"""
        try:
            if not self.vehicle:
                # print("âš ï¸ No vehicle available for control")
                return
            
            # print(f"ğŸ® Applying chase control to vehicle {self.vehicle.id}")
            
            # ì°¨ëŸ‰ ìƒíƒœ í™•ì¸
            vehicle_location = self.vehicle.get_location()
            vehicle_transform = self.vehicle.get_transform()
            # print(f"ğŸš— Vehicle location: {vehicle_location}")
            # print(f"ğŸš— Vehicle transform: {vehicle_transform}")
            
            # ì°¨ëŸ‰ì´ ì œì–´ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸
            if self.vehicle.is_at_traffic_light():
                # print("âš ï¸ Vehicle is at traffic light - control may be limited")
                pass
            
            # íƒ€ê²Ÿ ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ì  ê³„ì‚°
            bbox = target_obj['bbox_2d']
            target_center_x = bbox[0] + bbox[2] / 2
            target_center_y = bbox[1] + bbox[3] / 2
            
            # í™”ë©´ ì¤‘ì‹¬ì  (ì¹´ë©”ë¼ ê¸°ì¤€) - ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶¤
            if self.zenoh_camera_image is not None:
                screen_center_x = self.zenoh_camera_image.shape[1] / 2
                screen_center_y = self.zenoh_camera_image.shape[0] / 2
            else:
                screen_center_x = 800
                screen_center_y = 450
            
            # íƒ€ê²Ÿê³¼ í™”ë©´ ì¤‘ì‹¬ì˜ ì°¨ì´ ê³„ì‚°
            dx = target_center_x - screen_center_x
            dy = target_center_y - screen_center_y
            
            # print(f"ğŸ¯ Target center: ({target_center_x:.1f}, {target_center_y:.1f})")
            # print(f"ğŸ¯ Screen center: ({screen_center_x:.1f}, {screen_center_y:.1f})")
            # print(f"ğŸ¯ Offset: dx={dx:.1f}, dy={dy:.1f}")
            
            # ê°œì„ ëœ ì¡°í–¥ ê°ë„ ê³„ì‚°
            # íƒ€ê²Ÿì´ í™”ë©´ ì¤‘ì•™ì— ê°€ê¹Œìš°ë©´ ì§ì§„, ë©€ë¦¬ ìˆìœ¼ë©´ ì¡°í–¥
            steer_factor = dx / screen_center_x  # -1 ~ 1 ë²”ìœ„
            
            # ë¶€ë“œëŸ¬ìš´ ì¡°í–¥ì„ ìœ„í•œ ê°ì‡  ì ìš©
            steer_gain = 0.8  # ì¡°í–¥ ê°ë„ (ê¸°ì¡´ 1.5ì—ì„œ ê°ì†Œ)
            steer = max(-0.8, min(0.8, steer_factor * steer_gain))  # ìµœëŒ€ ì¡°í–¥ê° ì œí•œ
            
            # íƒ€ê²Ÿì´ í™”ë©´ ì¤‘ì•™ì— ê°€ê¹Œìš°ë©´ ì¡°í–¥ ê°ì†Œ
            center_tolerance = screen_center_x * 0.2  # í™”ë©´ ì¤‘ì‹¬ 20% ë²”ìœ„
            if abs(dx) < center_tolerance:
                steer *= 0.3  # ì¤‘ì•™ ê·¼ì²˜ì—ì„œëŠ” ì¡°í–¥ í¬ê²Œ ê°ì†Œ
            
            # ì†ë„ ì œì–´ (ê±°ë¦¬ì™€ íƒ€ê²Ÿ í¬ê¸° ê¸°ë°˜)
            target_size = bbox[2] * bbox[3]
            distance = target_obj.get('distance_estimate', 50)
            
            # ê±°ë¦¬ê°€ ê°€ê¹Œìš°ë©´ ì²œì²œíˆ, ë©€ë©´ ë¹ ë¥´ê²Œ
            if distance <= 30:
                throttle = 0.2  # ë§¤ìš° ì²œì²œíˆ
                brake = 0.1     # ì•½ê°„ ë¸Œë ˆì´í¬
            elif distance <= 50:
                throttle = 0.4  # ì²œì²œíˆ
                brake = 0.0
            else:
                throttle = 0.6  # ë³´í†µ ì†ë„
                brake = 0.0
            
            # íƒ€ê²Ÿ í¬ê¸°ê°€ ë§¤ìš° í¬ë©´ ì¶”ê°€ë¡œ ê°ì†
            if target_size > 20000:
                throttle *= 0.7
                brake = 0.1
            
            # print(f"ğŸ® Control calculation: steer_factor={steer_factor:.3f}, "
            #       f"distance={distance}m, target_size={target_size}")
            
            # CARLA ì œì–´ ëª…ë ¹ ìƒì„±
            control = carla.VehicleControl()
            control.throttle = throttle
            control.steer = steer
            control.brake = brake
            control.hand_brake = False
            control.reverse = False
            
            # ì œì–´ ëª…ë ¹ ì ìš©
            # print(f"ğŸ® Applying control to vehicle: throttle={throttle:.2f}, "
            #       f"steer={steer:.2f}, brake={brake:.2f}")
            self.vehicle.apply_control(control)
            
            # ì°¨ëŸ‰ ì†ë„ í™•ì¸
            velocity = self.vehicle.get_velocity()
            speed = (velocity.x**2 + velocity.y**2 + velocity.z**2)**0.5
            # print(f"ğŸš— Vehicle speed: {speed:.2f} m/s")
            
            # Zenohë¡œë„ ì œì–´ ëª…ë ¹ ë°œí–‰
            self.publish_control_command(control)
            
        except Exception as e:
            # print(f"âš ï¸ Error applying simple chase control: {e}")
            import traceback
            traceback.print_exc()
    
    def find_existing_vehicle(self):
        """ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ì°¨ëŸ‰ì„ ì°¾ì•„ì„œ ì œì–´"""
        try:
            # CARLA ì›”ë“œì˜ ëª¨ë“  ì•¡í„° ê°€ì ¸ì˜¤ê¸°
            actors = self.world.get_actors()
            vehicles = []
            
            # ëª¨ë“  ì°¨ëŸ‰ ì°¾ê¸°
            for actor in actors:
                if 'vehicle' in actor.type_id:
                    vehicles.append(actor)
                    # print(f"ğŸš— Found vehicle: {actor.type_id} (ID: {actor.id}) at {actor.get_location()}")
            
            if not vehicles:
                # print("âŒ No existing vehicles found in CARLA world")
                return False
            
            # ì²« ë²ˆì§¸ ì°¨ëŸ‰ì„ chase vehicleë¡œ ì‚¬ìš©
            self.vehicle = vehicles[0]
            # print(f"âœ… Using existing vehicle: {self.vehicle.type_id} (ID: {self.vehicle.id})")
            # print(f"ğŸ“ Vehicle location: {self.vehicle.get_location()}")
            
            return True
            
        except Exception as e:
            # print(f"âŒ Error spawning chase vehicle: {e}")
            return False
    
    def setup_camera(self):
        """ì¶”ê²©ì°¨ëŸ‰ ì¹´ë©”ë¼ ì„¤ì •"""
        try:
            # ìµœì í™”ëœ ê³ ì„±ëŠ¥ ì¹´ë©”ë¼ ë·° ì‚¬ìš©
            self.camera_view = OptimizedCameraView(
                self.world, 
                self.vehicle, 
                "Auto Chase Vehicle Camera View",
                enable_bounding_boxes=True,  # ë°”ìš´ë”© ë°•ìŠ¤ í™œì„±í™”
                enable_zenoh=True           # Zenoh í™œì„±í™”
            )
            
            # ì¹´ë©”ë¼ ì„¤ì •
            camera_location = carla.Location(x=1.5, z=1.4)
            camera_rotation = carla.Rotation(pitch=0, yaw=0, roll=0)
            
            if self.camera_view.setup_camera(camera_location, camera_rotation):
                # ì¹´ë©”ë¼ ì½œë°± ì„¤ì •ì„ ë‚˜ì¤‘ì— ì²˜ë¦¬ (segfault ë°©ì§€)
                self.camera_view.latest_image = None  # ìµœì‹  ì´ë¯¸ì§€ ì €ì¥ ë³€ìˆ˜ ì´ˆê¸°í™”
                
                print("ğŸ“· Chase vehicle camera attached with bounding box detection")
                print("ğŸ“· Camera callback will be set up after modules initialization")
                return True
            else:
                return False
            
        except Exception as e:
            print(f"âŒ Error setting up camera: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def setup_imu_sensor(self):
        """IMU ì„¼ì„œ ì„¤ì •"""
        try:
            # IMU ì„¼ì„œ ë¸”ë£¨í”„ë¦°íŠ¸ ê°€ì ¸ì˜¤ê¸°
            imu_bp = self.world.get_blueprint_library().find('sensor.other.imu')
            if imu_bp is None:
                print("âš ï¸ IMU sensor blueprint not found")
                return False
            
            # IMU ì„¼ì„œ ìŠ¤í°
            imu_transform = carla.Transform()
            self.imu_sensor = self.world.spawn_actor(imu_bp, imu_transform, attach_to=self.vehicle)
            
            # IMU ë°ì´í„° ì½œë°± ì„¤ì •
            self.imu_sensor.listen(self.on_imu_data)
            
            print("ğŸ§­ IMU sensor attached")
            return True
            
        except Exception as e:
            print(f"âŒ Error setting up IMU sensor: {e}")
            return False
    
    def on_imu_data(self, imu_data):
        """IMU ë°ì´í„° ì½œë°±"""
        try:
            self.current_imu_data = {
                'accelerometer': (imu_data.accelerometer.x, imu_data.accelerometer.y, imu_data.accelerometer.z),
                'gyroscope': (imu_data.gyroscope.x, imu_data.gyroscope.y, imu_data.gyroscope.z),
                'compass': imu_data.compass,
                'timestamp': imu_data.timestamp
            }
        except Exception as e:
            print(f"âš ï¸ Error processing IMU data: {e}")
    
    def setup_camera_callback(self):
        """ì¹´ë©”ë¼ ì½œë°± ì„¤ì • (segfault ë°©ì§€ë¥¼ ìœ„í•´ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬)"""
        try:
            if self.camera_view and self.camera_view.camera:
                print("ğŸ“· Setting up camera callback...")
                
                # ì¹´ë©”ë¼ê°€ ì´ë¯¸ ë‹¤ë¥¸ ì½œë°±ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
                if hasattr(self.camera_view.camera, '_listeners'):
                    print(f"ğŸ“· Camera has {len(self.camera_view.camera._listeners)} existing listeners")
                
                # ì½œë°± ì„¤ì •ì„ ì‹œë„í•˜ì§€ ì•Šê³  Zenoh ì¹´ë©”ë¼ ë°ì´í„°ë§Œ ì‚¬ìš©
                print("ğŸ“· Skipping CARLA camera callback to avoid segfault")
                print("ğŸ“· Using Zenoh camera data only (like web dashboard)")
                
                # Zenoh ì¹´ë©”ë¼ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
                self.use_zenoh_camera_only = True
                
                # Pygame ì´ˆê¸°í™” (pygame view í‘œì‹œìš©)
                try:
                    if not pygame.get_init():
                        pygame.init()
                    print("âœ… Pygame initialized for camera view")
                except Exception as e:
                    print(f"âš ï¸ Pygame initialization error: {e}")
                
            else:
                print("âš ï¸ Camera view or camera not available for callback setup")
                
        except Exception as e:
            print(f"âŒ Error setting up camera callback: {e}")
            import traceback
            traceback.print_exc()
            
            # ì½œë°± ì„¤ì • ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆìœ¼ë¡œ Zenoh ì¹´ë©”ë¼ ë°ì´í„°ë§Œ ì‚¬ìš©
            print("ğŸ“· Falling back to Zenoh camera data only")
    
    def on_camera_image(self, carla_image):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì½œë°± - ì¶”ê²©ì°¨ì˜ ì¹´ë©”ë¼ì—ì„œ ë°›ì€ ì´ë¯¸ì§€"""
        try:
            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            if not hasattr(carla_image, 'width') or not hasattr(carla_image, 'height'):
                print("âš ï¸ Invalid camera image object")
                return
                
            print(f"ğŸ“· Camera callback received: {carla_image.width}x{carla_image.height}")
            
            # raw_data í™•ì¸
            if not hasattr(carla_image, 'raw_data') or carla_image.raw_data is None:
                print("âš ï¸ No raw_data in camera image")
                return
            
            # CARLA ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            array = np.frombuffer(carla_image.raw_data, dtype=np.uint8)
            
            # ì´ë¯¸ì§€ í¬ê¸° ê²€ì¦
            expected_size = carla_image.height * carla_image.width * 4  # RGBA
            if len(array) != expected_size:
                print(f"âš ï¸ Image size mismatch: expected {expected_size}, got {len(array)}")
                return
            
            array = array.reshape((carla_image.height, carla_image.width, 4))
            array = array[:, :, :3]  # RGBë§Œ ì‚¬ìš© (A ì±„ë„ ì œê±°)
            array = array[:, :, ::-1]  # RGBë¥¼ BGRë¡œ ë³€í™˜ (OpenCV í˜•ì‹)
            
            print(f"ğŸ“· Converted image shape: {array.shape}")
            
            # ìµœì‹  ì´ë¯¸ì§€ë¡œ ì €ì¥ (thread-safe)
            if self.camera_view:
                self.camera_view.latest_image = array.copy()  # ë³µì‚¬ë³¸ ì €ì¥
                print("âœ… Camera image stored")
                
        except Exception as e:
            print(f"âš ï¸ Error processing camera image: {e}")
            # Core dump ë°©ì§€ë¥¼ ìœ„í•´ traceback ì¶œë ¥ì„ ìµœì†Œí™”
            print(f"âš ï¸ Image object type: {type(carla_image)}")
            print(f"âš ï¸ Image attributes: {dir(carla_image) if hasattr(carla_image, '__dict__') else 'N/A'}")
    
    def setup_modules(self):
        """ëª¨ë“ˆë“¤ ì´ˆê¸°í™”"""
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤ ê°ì§€ê¸° ì´ˆê¸°í™”
            if self.camera_view and self.camera_view.camera:
                self.bounding_box_detector = BoundingBoxDetector(self.world, self.camera_view.camera)
                print("ğŸ¯ Bounding box detector initialized")
            
            # ì¶©ëŒ ê°ì§€ê¸° ì´ˆê¸°í™”
            self.collision_detector = CollisionDetector()
            print("ğŸš¨ Collision detector initialized")
            
            # ì¶©ëŒ ì°¨ëŸ‰ ì¶”ì ê¸° ì´ˆê¸°í™”
            self.vehicle_tracker = CollisionVehicleTracker(self.world)
            print("ğŸ¯ Vehicle tracker initialized")
            
            # ë‹¨ìˆœ ì¶”ê²© ê³„íšì ì´ˆê¸°í™”
            self.chase_planner = SimpleChasePlanner(self.world, self.vehicle, self.world.get_map())
            # ì¶”ê²© íŒŒë¼ë¯¸í„° ì„¤ì • (ì†ë„ ë”ìš± ê°ì†Œ)
            self.chase_planner.set_chase_parameters(
                max_speed=8.0,         # ìµœëŒ€ ì†ë„ (29km/h) - ë§¤ìš° ì•ˆì „í•œ ì†ë„
                min_distance=5.0,      # 5m ì´ë‚´ì—ì„œ ë°•ê¸° - ë” ì•ˆì „í•œ ê±°ë¦¬
                chase_distance=100.0   # 100m ì´ë‚´ì—ì„œ ì¶”ê²©
            )
            # ì¡°í–¥ ë°©í–¥ ì •ìƒ ì„¤ì • (íƒ€ê²Ÿì„ ë”°ë¼ê°€ë„ë¡)
            self.chase_planner.set_steering_direction(1)
            
            # Set control publisher callback
            self.chase_planner.set_control_publisher_callback(self.publish_control_command)
            
            print("ğŸ§  Chase planner initialized with high-speed parameters")
            
            # ì°¨ëŸ‰ ì œì–´ê¸° ì´ˆê¸°í™” (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - SimpleChasePlannerì—ì„œ ì§ì ‘ ì œì–´)
            # self.vehicle_controller = ChaseVehicleController(self.world, self.vehicle)
            # print("ğŸ® Vehicle controller initialized")
            
            print("âœ… All modules initialized")
            
            # ì¹´ë©”ë¼ ì½œë°± ì„¤ì • (ëª¨ë“ˆ ì´ˆê¸°í™” í›„)
            self.setup_camera_callback()
            
            return True
            
        except Exception as e:
            print(f"âŒ Error setting up modules: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def update_perception(self):
        """ì¸ì‹ ëª¨ë“ˆ ì—…ë°ì´íŠ¸"""
        try:
            if not self.bounding_box_detector:
                return []
            
            # ê°ì²´ ê°ì§€ (ë²”ìœ„ í™•ì¥)
            detected_objects = self.bounding_box_detector.detect_pedestrians_and_vehicles(max_distance=200.0)
            self.chase_statistics['total_detections'] = len(detected_objects)
            
            # ì¶©ëŒ ê°ì§€
            collision_events = self.collision_detector.analyze_pedestrian_collision(detected_objects)
            if collision_events:
                self.chase_statistics['collision_events'] += len(collision_events)
                print(f"ğŸš¨ Collision detected: {len(collision_events)} events")
            
            return detected_objects, collision_events
            
        except Exception as e:
            print(f"âš ï¸ Error updating perception: {e}")
            return [], []
    
    def update_tracking(self, detected_objects, collision_events):
        """ì¶”ì  ëª¨ë“ˆ ì—…ë°ì´íŠ¸"""
        try:
            if not self.vehicle_tracker:
                return False
            
            # ì¶©ëŒ ì°¨ëŸ‰ ê°ì§€ ë° ì¶”ì  ì‹œì‘
            if collision_events:
                print(f"ğŸš¨ Collision events detected: {len(collision_events)}")
                tracking_started = self.vehicle_tracker.detect_collision_vehicle(detected_objects, collision_events)
                print(f"ğŸ¯ Tracking started: {tracking_started}")
            
            # ì¶”ì  ì—…ë°ì´íŠ¸ (ì¶”ì  ì¤‘ì´ê±°ë‚˜ ë°©ê¸ˆ ì‹œì‘ëœ ê²½ìš°)
            if self.vehicle_tracker.is_tracking:
                is_tracking = self.vehicle_tracker.update_tracking(detected_objects)
                print(f"ğŸ¯ Tracking update result: {is_tracking}")
                return is_tracking
            else:
                # ì¶©ëŒì´ ê°ì§€ëœ ê²½ìš°ì—ë§Œ ì¶”ê²© ì‹œì‘
                if collision_events:
                    print(f"ğŸš¨ Collision detected - starting chase")
                    # ì¶©ëŒ ì´ë²¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê²© ì‹œì‘
                    if detected_objects:
                        target_vehicle = detected_objects[0]
                        self.vehicle_tracker.start_tracking(target_vehicle)
                        return True
                else:
                    print(f"ğŸš— Vehicles detected but no collision - waiting for collision event")
                    return False
            
            return False
            
        except Exception as e:
            print(f"âš ï¸ Error updating tracking: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def update_planning_and_control(self):
        """ê³„íš ë° ì œì–´ ëª¨ë“ˆ ì—…ë°ì´íŠ¸"""
        try:
            print(f"ğŸ¯ Planning and control update: tracker={self.vehicle_tracker is not None}, is_tracking={self.vehicle_tracker.is_tracking if self.vehicle_tracker else False}")
            
            if not self.vehicle_tracker or not self.vehicle_tracker.is_tracking:
                # ì¶”ê²© ì¤‘ì´ ì•„ë‹Œ ê²½ìš° ëŒ€ê¸°
                print("ğŸ›‘ Not tracking - waiting for target")
                self._wait_for_target()
                return
            
            # íƒ€ê²Ÿ ì°¨ëŸ‰ ê°€ì ¸ì˜¤ê¸°
            target_vehicle = self.vehicle_tracker.get_target_vehicle()
            if not target_vehicle:
                print("âš ï¸ No target vehicle from tracker")
                return
            
            print(f"ğŸ¯ Target vehicle: {target_vehicle}")
            
            # í˜„ì¬ ìœ„ì¹˜ì™€ íšŒì „
            current_location = self.vehicle.get_location()
            current_rotation = self.vehicle.get_transform().rotation
            
            # ì¶”ê²© ì‹œì‘ (í•œ ë²ˆë§Œ)
            if not self.is_chasing:
                self.chase_planner.start_chase(target_vehicle)
                self.is_chasing = True
                print("ğŸ¯ Started chasing target vehicle")
            
            # íƒ€ê²Ÿ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
            if isinstance(target_vehicle, dict) and 'world_location' in target_vehicle:
                target_location = carla.Location(
                    x=target_vehicle['world_location'][0],
                    y=target_vehicle['world_location'][1],
                    z=target_vehicle['world_location'][2]
                )
            else:
                target_location = target_vehicle.get_location()
            
            # IMU ë°ì´í„° ì „ë‹¬
            imu_data = self.current_imu_data if self.current_imu_data else None
            
            # íƒ€ê²Ÿ ë°”ìš´ë”© ë°•ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            target_bbox = None
            if isinstance(target_vehicle, dict) and 'bbox_2d' in target_vehicle:
                target_bbox = target_vehicle['bbox_2d']
                print(f"ğŸ“· Using target bbox: {target_bbox}")
            else:
                print("âš ï¸ No target bbox available")
            
            # ì¹´ë©”ë¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            camera_info = None
            if self.camera_view and self.camera_view.camera:
                camera_info = {
                    'width': int(self.camera_view.camera.attributes['image_size_x']),
                    'height': int(self.camera_view.camera.attributes['image_size_y'])
                }
                print(f"ğŸ“· Camera info: {camera_info['width']}x{camera_info['height']}")
            
            # ì¹´ë©”ë¼ ê¸°ë°˜ ì¶”ê²© ê³„íš ìˆ˜ë¦½ ë° ì§ì ‘ ì œì–´ ì ìš©
            control_command = self.chase_planner.plan_chase_behavior(
                current_location, current_rotation, target_location, None, imu_data, target_bbox, camera_info
            )
            
            # SimpleChasePlannerì—ì„œ ì´ë¯¸ vehicle.apply_control()ì„ í˜¸ì¶œí•˜ë¯€ë¡œ ë³„ë„ ì ìš© ë¶ˆí•„ìš”
            # self._apply_control_command(control_command)
            
            # ìƒíƒœ ì¶œë ¥
            status = self.chase_planner.get_chase_status()
            print(f"ğŸ¯ {status}")
            
        except Exception as e:
            print(f"âš ï¸ Error updating planning and control: {e}")
            import traceback
            traceback.print_exc()
            self._emergency_stop()
    
    def _wait_for_target(self):
        """íƒ€ê²Ÿ ëŒ€ê¸°"""
        try:
            # ì¶”ê²© ì¤‘ì´ì—ˆë‹¤ë©´ ì¤‘ì§€
            if self.is_chasing:
                self.is_chasing = False
                print("ğŸ¯ Stopped chasing - waiting for target")
            
            # SimpleChasePlannerì˜ stop_controlì„ ì‚¬ìš©í•˜ì—¬ ì œì–´
            if self.chase_planner:
                self.chase_planner.stop_chase()
            
        except Exception as e:
            print(f"âš ï¸ Error in wait mode: {e}")
    
    # _apply_control_command í•¨ìˆ˜ ì œê±° - SimpleChasePlannerì—ì„œ ì§ì ‘ ì œì–´
    
    def publish_control_command(self, control_command):
        """Publish control command to Zenoh for target vehicle"""
        try:
            if not self.zenoh_session or not self.target_vehicle_id:
                return

            # Create control message
            control_data = {
                'target_vehicle_id': self.target_vehicle_id,
                'throttle': float(control_command.throttle),
                'steer': float(control_command.steer),
                'brake': float(control_command.brake),
                'hand_brake': bool(control_command.hand_brake),
                'reverse': bool(control_command.reverse),
                'manual_gear_shift': bool(control_command.manual_gear_shift),
                'gear': int(control_command.gear) if control_command.manual_gear_shift else 0,
                'timestamp': time.time()
            }

            # Publish to Zenoh
            self.zenoh_session.put("carla/vehicle/control", json.dumps(control_data))
            print(f"ğŸ“¡ Published control command for vehicle {self.target_vehicle_id}: "
                  f"throttle={control_data['throttle']:.2f}, steer={control_data['steer']:.2f}, brake={control_data['brake']:.2f}")

        except Exception as e:
            print(f"âš ï¸ Error publishing control command: {e}")
    
    def _update_chase_statistics(self, target_distance):
        """ì¶”ê²© í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            # í˜„ì¬ ì†ë„ ê³„ì‚°
            current_velocity = self.vehicle.get_velocity()
            current_speed = np.linalg.norm([current_velocity.x, current_velocity.y, current_velocity.z])
            
            # ìµœëŒ€ ì†ë„ ì—…ë°ì´íŠ¸
            if current_speed > self.chase_statistics['max_speed_reached']:
                self.chase_statistics['max_speed_reached'] = current_speed
            
            # ì¶”ê²© ê±°ë¦¬ ì—…ë°ì´íŠ¸
            self.chase_statistics['chase_distance'] = target_distance
            
            # ì¶”ê²© ì‹œê°„ ì—…ë°ì´íŠ¸
            if self.is_chasing:
                self.chase_statistics['tracking_duration'] += self.update_interval
            
        except Exception as e:
            print(f"âš ï¸ Error updating statistics: {e}")
    
    def _print_chase_status(self, target_distance):
        """ì¶”ê²© ìƒíƒœ ì¶œë ¥"""
        try:
            # 5ì´ˆë§ˆë‹¤ ìƒíƒœ ì¶œë ¥
            if int(time.time()) % 5 == 0:
                current_velocity = self.vehicle.get_velocity()
                current_speed = np.linalg.norm([current_velocity.x, current_velocity.y, current_velocity.z])
                
                print(f"ğŸ¯ Chase Status: Distance={target_distance:.1f}m, Speed={current_speed:.1f}m/s")
                
                # ì¶”ì  ìƒíƒœ ì¶œë ¥
                if self.vehicle_tracker:
                    tracking_status = self.vehicle_tracker.get_tracking_status()
                    print(f"   Tracking: {tracking_status['is_tracking']}, Duration: {tracking_status['track_duration']:.1f}s")
                
                # ì¶”ê²© ìƒíƒœ ì¶œë ¥
                if self.chase_planner:
                    chase_status = self.chase_planner.get_chase_status()
                    print(f"   State: {chase_status['current_state']}, Duration: {chase_status['state_duration']:.1f}s")
            
        except Exception as e:
            print(f"âš ï¸ Error printing chase status: {e}")
    
    def _emergency_stop(self):
        """ë¹„ìƒ ì •ì§€"""
        try:
            # SimpleChasePlannerì˜ stop_controlì„ ì‚¬ìš©í•˜ì—¬ ì œì–´
            if self.chase_planner:
                self.chase_planner.stop_chase()
            
            print("ğŸ›‘ Emergency stop applied")
            
        except Exception as e:
            print(f"âš ï¸ Error applying emergency stop: {e}")
    
    
    def display_camera_view(self):
        """ì¹´ë©”ë¼ ë·° í‘œì‹œ (pygameë§Œ ì‚¬ìš©)"""
        try:
            # Zenoh ì¹´ë©”ë¼ ê¸°ë°˜ ì‹œìŠ¤í…œì¸ ê²½ìš°
            if self.use_zenoh_camera_only:
                # Pygame viewë§Œ í‘œì‹œ (OpenCV ìœˆë„ìš° ì œê±°)
                if self.camera_view and self.zenoh_camera_image is not None:
                    self.camera_view.set_zenoh_camera_data(
                        self.zenoh_camera_image, 
                        self.zenoh_detected_objects
                    )
                    self.camera_view.display_camera_view()
            else:
                # ê¸°ì¡´ CARLA ì¹´ë©”ë¼ ë°©ì‹
                if self.camera_view:
                    # Zenoh ì¹´ë©”ë¼ ë°ì´í„°ë¥¼ OptimizedCameraViewì— ë™ê¸°í™”
                    if self.zenoh_camera_image is not None:
                        self.camera_view.set_zenoh_camera_data(
                            self.zenoh_camera_image, 
                            self.zenoh_detected_objects
                        )
                    
                    # HUD ì •ë³´ ì—…ë°ì´íŠ¸
                    if self.vehicle_tracker and self.vehicle_tracker.is_tracking:
                        target_position = self.vehicle_tracker.get_target_position()
                        target_distance = self.vehicle_tracker.get_target_distance(self.vehicle.get_transform().location)
                        
                        if target_position:
                            self.camera_view.set_hud_info(
                                Target=f"({target_position[0]:.1f}, {target_position[1]:.1f}, {target_position[2]:.1f})",
                                Distance=f"{target_distance:.1f} m",
                                Objects=f"{self.chase_statistics['total_detections']} | Collisions: {self.chase_statistics['collision_events']}"
                            )
                    
                    # OptimizedCameraViewì˜ display_camera_view í˜¸ì¶œ (pygameë§Œ ì‚¬ìš©)
                    self.camera_view.display_camera_view()
            
        except Exception as e:
            print(f"âš ï¸ Error displaying camera view: {e}")
    
    def display_chase_vehicle_camera(self):
        """Display chase vehicle's camera view - DISABLED (pygame only)"""
        # OpenCV ìœˆë„ìš°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - pygameë§Œ ì‚¬ìš©
        pass
    
    def display_zenoh_camera_view(self):
        """Display Zenoh camera view - DISABLED (pygame only)"""
        # OpenCV ìœˆë„ìš°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - pygameë§Œ ì‚¬ìš©
        pass
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        try:
            print("ğŸš€ Starting Auto Chase Vehicle Control...")
            
            # CARLA ì—°ê²°
            if not self.connect_to_carla():
                return
            
            # Zenoh ì„¤ì •
            self.setup_zenoh()
            
            # ê¸°ì¡´ ì°¨ëŸ‰ ì°¾ê¸°
            if not self.find_existing_vehicle():
                return
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.setup_camera()
            
            # IMU ì„¼ì„œ ì„¤ì •
            self.setup_imu_sensor()
            
            # ì¹´ë©”ë¼ ì½œë°± ì„¤ì •
            self.setup_camera_callback()
            
            # ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
            self.setup_modules()
            
            # Zenoh êµ¬ë…ì ì„¤ì •
            if self.zenoh_session:
                # ì°¨ëŸ‰ í…”ë ˆë©”íŠ¸ë¦¬ êµ¬ë…
                telemetry_subscriber = self.zenoh_session.declare_subscriber(
                    "carla/vehicle/telemetry",
                    self.on_vehicle_id_received
                )
                self.zenoh_subscribers.append(telemetry_subscriber)
                
                # ì¹´ë©”ë¼ ì´ë¯¸ì§€ êµ¬ë…
                camera_subscriber = self.zenoh_session.declare_subscriber(
                    "carla/vehicle/camera",
                    self.on_camera_image_received
                )
                self.zenoh_subscribers.append(camera_subscriber)
                
                print("ğŸ“¡ Zenoh subscribers configured")
            
            print("ğŸ® CONTROLS:")
            print("  ESC - Exit")
            print("  C - Manual collision trigger (disabled)")
            
            # ë©”ì¸ ë£¨í”„
            while self.running:
                try:
                    # ì…ë ¥ ì²˜ë¦¬
                    for event in pygame.event.get():
                        if event.type == pygame.QUIT:
                            self.running = False
                            break
                        elif event.type == pygame.KEYDOWN:
                            if event.key == pygame.K_ESCAPE:
                                self.running = False
                                break
                    
                    if not self.running:
                        break
                    
                    current_time = time.time()
                    
                    # ì—…ë°ì´íŠ¸ ê°„ê²© ì²´í¬
                    if current_time - self.last_update_time < self.update_interval:
                        time.sleep(0.01)  # 10ms ëŒ€ê¸°
                        continue
                    
                    # 1. ì¸ì‹ ì—…ë°ì´íŠ¸
                    detected_objects, collision_events = self.update_perception()
                    
                    # 2. ì¶”ì  ì—…ë°ì´íŠ¸
                    is_tracking = self.update_tracking(detected_objects, collision_events)
                    # print(f"ğŸ¯ Main loop - is_tracking: {is_tracking}")
                    
                    # Zenoh ì¹´ë©”ë¼ ê¸°ë°˜ ì¶”ê²© ì œì–´ (ì¶”ê°€)
                    if self.use_zenoh_camera_only:
                        # print(f"ğŸš” Zenoh-based chase control: {len(self.zenoh_detected_objects)} objects detected")
                        # print(f"ğŸš” Chase status check: is_chasing={self.is_chasing}, collisions={self.chase_statistics['collision_events']}")
                        self.handle_zenoh_chase_control()
                    
                    # 3. ê³„íš ë° ì œì–´ ì—…ë°ì´íŠ¸
                    self.update_planning_and_control()
                    
                    # 4. ì¹´ë©”ë¼ ë·° í‘œì‹œ (ë‹¨ì¼ ìœˆë„ìš°)
                    try:
                        self.display_camera_view()
                    except Exception as display_error:
                        print(f"âš ï¸ Camera display error: {display_error}")
                    
                    self.last_update_time = current_time
                    
                except KeyboardInterrupt:
                    print("\nğŸ›‘ Auto chase vehicle control interrupted by user")
                    break
                except Exception as e:
                    print(f"âš ï¸ Error in main loop: {e}")
                    time.sleep(0.1)
            
        except Exception as e:
            print(f"âŒ Error in main execution: {e}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            print("\nğŸ§¹ Cleaning up resources...")
            
            # ëª¨ë“ˆë“¤ ì •ë¦¬
            if self.vehicle_tracker:
                self.vehicle_tracker.reset_tracking()
            if self.chase_planner:
                self.chase_planner.reset_chase()
            
            # ì¹´ë©”ë¼ ë·° ì •ë¦¬
            if self.camera_view:
                self.camera_view.cleanup()
                self.camera_view = None
            
            # ì°¨ëŸ‰ ì •ë¦¬ (destroyí•˜ì§€ ì•ŠìŒ - ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŒ)
            if self.vehicle:
                print(f"â„¹ï¸ Not destroying vehicle {self.vehicle.id} (may be used by other systems)")
                self.vehicle = None
            
            # Zenoh ì •ë¦¬
            for subscriber in self.zenoh_subscribers:
                subscriber.undeclare()
            if self.zenoh_session:
                self.zenoh_session.close()
            
            # OpenCV ì°½ ì •ë¦¬ (ê°•í™”)
            print("ğŸ§¹ Cleaning up OpenCV windows...")
            cv2.destroyAllWindows()
            cv2.waitKey(1)  # ìœˆë„ìš° ì •ë¦¬ë¥¼ ìœ„í•œ ì¶”ê°€ ëŒ€ê¸°
            
            # ëª¨ë“  OpenCV ìœˆë„ìš° ê°•ì œ ì¢…ë£Œ
            try:
                # íŠ¹ì • ìœˆë„ìš° ì´ë¦„ìœ¼ë¡œ ì¢…ë£Œ ì‹œë„
                cv2.destroyWindow("Chase Vehicle Camera")
                cv2.destroyWindow("Zenoh Camera View")
                cv2.destroyWindow("Camera View")
            except:
                pass  # ìœˆë„ìš°ê°€ ì—†ì–´ë„ ë¬´ì‹œ
            
            # ì¶”ê°€ ëŒ€ê¸° ì‹œê°„
            time.sleep(0.1)
            
            print("âœ… Cleanup completed")
            
        except Exception as e:
            print(f"âš ï¸ Error during cleanup: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    auto_chase_control = None
    try:
        auto_chase_control = AutoChaseVehicleControl()
        auto_chase_control.run()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Interrupted by user")
    except Exception as e:
        print(f"âŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # í™•ì‹¤í•œ ì •ë¦¬
        if auto_chase_control:
            auto_chase_control.cleanup()
        cleanup_opencv_windows()
        print("ğŸ‘‹ Goodbye!")

if __name__ == "__main__":
    main()
