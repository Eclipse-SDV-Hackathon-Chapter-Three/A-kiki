#!/usr/bin/env python3
"""
LiDAR Visualization Module
LiDAR í¬ì¸íŠ¸ë¥¼ ì¹´ë©”ë¼ í™”ë©´ì— ì˜¤ë²„ë ˆì´í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import numpy as np
import pygame
from typing import List, Dict, Tuple, Optional


class LiDARVisualizer:
    """LiDAR í¬ì¸íŠ¸ ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.lidar_points_2d = []  # 2D íˆ¬ì˜ëœ LiDAR í¬ì¸íŠ¸ë“¤
        self.lidar_colors = []  # LiDAR í¬ì¸íŠ¸ ìƒ‰ìƒë“¤
        self.show_lidar_overlay = True  # LiDAR ì˜¤ë²„ë ˆì´ í‘œì‹œ ì—¬ë¶€
        
        # Semantic í•„í„°ë§
        self.target_semantic_classes = {
            'vehicle': 10,      # ì°¨ëŸ‰
            'lane_marking': 6,  # ì°¨ì„ 
            'pedestrian': 4     # ë³´í–‰ì
        }
        
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì •ì˜
        self.class_colors = {
            'vehicle': (255, 0, 0),      # ë¹¨ê°„ìƒ‰ - ì°¨ëŸ‰
            'lane_marking': (0, 255, 0), # ë…¹ìƒ‰ - ì°¨ì„ 
            'pedestrian': (0, 0, 255)    # íŒŒë€ìƒ‰ - ë³´í–‰ì
        }
    
    def filter_semantic_lidar_data(self, semantic_lidar_data: List[Dict]) -> List[Dict]:
        """Semantic LiDAR ë°ì´í„° í•„í„°ë§ (ëª¨ë“  í¬ì¸íŠ¸ í‘œì‹œ)"""
        try:
            if not semantic_lidar_data:
                return []
            
            # ëª¨ë“  í¬ì¸íŠ¸ë¥¼ í‘œì‹œ (í•„í„°ë§ ì—†ìŒ)
            print(f"ğŸ” ëª¨ë“  LiDAR í¬ì¸íŠ¸ í‘œì‹œ: {len(semantic_lidar_data)}ê°œ")
            return semantic_lidar_data
            
        except Exception as e:
            print(f"âš ï¸ Error filtering semantic LiDAR data: {e}")
            return []
    
    def project_lidar_to_camera(self, lidar_points: List[List[float]], 
                               lidar_transform, camera_transform, camera_intrinsic: np.ndarray) -> Tuple[List, List]:
        """LiDAR 3D í¬ì¸íŠ¸ë¥¼ ì¹´ë©”ë¼ 2D ì¢Œí‘œë¡œ íˆ¬ì˜ (CARLA lidar_to_camera.py ì •í™•í•œ ë°©ì‹)"""
        try:
            if len(lidar_points) == 0:
                return [], []
            
            # LiDAR í¬ì¸íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            points = np.array(lidar_points)
            if len(points.shape) == 1:
                points = points.reshape(1, -1)
            
            print(f"ğŸ” íˆ¬ì˜ ì‹œë„: {len(points)}ê°œ í¬ì¸íŠ¸")
            print(f"   ì›ë³¸ í¬ì¸íŠ¸: x[{points[:, 0].min():.2f}, {points[:, 0].max():.2f}], y[{points[:, 1].min():.2f}, {points[:, 1].max():.2f}], z[{points[:, 2].min():.2f}, {points[:, 2].max():.2f}]")
            print(f"   LiDAR transform shape: {lidar_transform.shape}")
            print(f"   Camera transform type: {type(camera_transform)}, shape: {camera_transform.shape if hasattr(camera_transform, 'shape') else 'No shape'}")
            print(f"   Camera intrinsic shape: {camera_intrinsic.shape}")
            
            # camera_transformì„ numpy arrayë¡œ ë³€í™˜
            if not hasattr(camera_transform, 'shape'):
                camera_transform = np.array(camera_transform)
                print(f"   Camera transform converted to numpy array: {camera_transform.shape}")
            
            # CARLA lidar_to_camera.py ë°©ì‹ - ì •í™•íˆ ë™ì¼
            # 1. Point cloud in lidar sensor space array of shape (3, p_cloud_size)
            local_lidar_points = points.T  # (3, N)
            
            # 2. Add an extra 1.0 at the end of each 3d point so it becomes of shape (4, p_cloud_size)
            local_lidar_points = np.r_[local_lidar_points, [np.ones(local_lidar_points.shape[1])]]  # (4, N)
            
            # 3. This (4, 4) matrix transforms the points from lidar space to world space
            lidar_2_world = lidar_transform
            
            # 4. Transform the points from lidar space to world space
            world_points = np.dot(lidar_2_world, local_lidar_points)
            
            # 5. This (4, 4) matrix transforms the points from world to sensor coordinates
            world_2_camera = np.array(camera_transform)
            
            # 6. Transform the points from world space to camera space
            sensor_points = np.dot(world_2_camera, world_points)
            
            # 7. Change from UE4's coordinate system to an "standard" camera coordinate system (OpenCV)
            # (x, y, z) -> (y, -z, x)
            point_in_camera_coords = np.array([
                sensor_points[1],      # y -> x
                sensor_points[2] * -1, # -z -> y  
                sensor_points[0]       # x -> z
            ])
            
            print(f"   ì¹´ë©”ë¼ ì¢Œí‘œê³„ ë³€í™˜ í›„: x[{point_in_camera_coords[0].min():.2f}, {point_in_camera_coords[0].max():.2f}], y[{point_in_camera_coords[1].min():.2f}, {point_in_camera_coords[1].max():.2f}], z[{point_in_camera_coords[2].min():.2f}, {point_in_camera_coords[2].max():.2f}]")
            
            # 8. Finally we can use our K matrix to do the actual 3D -> 2D
            points_2d = np.dot(camera_intrinsic, point_in_camera_coords)
            
            # 9. Remember to normalize the x, y values by the 3rd value
            points_2d = np.array([
                points_2d[0, :] / points_2d[2, :],
                points_2d[1, :] / points_2d[2, :],
                points_2d[2, :]
            ])
            
            # 10. At this point, points_2d[0, :] contains all the x and points_2d[1, :] contains all the y values
            points_2d = points_2d.T
            
            print(f"   2D íˆ¬ì˜ í›„: x[{points_2d[:, 0].min():.2f}, {points_2d[:, 0].max():.2f}], y[{points_2d[:, 1].min():.2f}, {points_2d[:, 1].max():.2f}], z[{points_2d[:, 2].min():.2f}, {points_2d[:, 2].max():.2f}]")
            
            # ìƒ˜í”Œ í¬ì¸íŠ¸ë“¤ ì¶œë ¥ (ì²˜ìŒ 5ê°œ)
            print(f"   ìƒ˜í”Œ 2D í¬ì¸íŠ¸ë“¤:")
            for i in range(min(5, len(points_2d))):
                print(f"     í¬ì¸íŠ¸ {i}: ({points_2d[i, 0]:.1f}, {points_2d[i, 1]:.1f}, {points_2d[i, 2]:.1f})")
            
            # 11. Filter points that are out of the screen and behind the camera projection plane
            image_w, image_h = 1080, 720  # ì¹´ë©”ë¼ í•´ìƒë„
            points_in_canvas_mask = (
                (points_2d[:, 0] > 0.0) & (points_2d[:, 0] < image_w) &
                (points_2d[:, 1] > 0.0) & (points_2d[:, 1] < image_h) &
                (np.abs(points_2d[:, 2]) > 0.1)  # zê°’ì´ 0ì— ë„ˆë¬´ ê°€ê¹ì§€ ì•Šì€ í¬ì¸íŠ¸ (ìŒìˆ˜ í—ˆìš©)
            )
            
            print(f"   í•„í„°ë§ ì¡°ê±´ í™•ì¸:")
            print(f"     x ë²”ìœ„: {points_2d[:, 0].min():.2f} ~ {points_2d[:, 0].max():.2f} (0 ~ {image_w})")
            print(f"     y ë²”ìœ„: {points_2d[:, 1].min():.2f} ~ {points_2d[:, 1].max():.2f} (0 ~ {image_h})")
            print(f"     z ë²”ìœ„: {points_2d[:, 2].min():.2f} ~ {points_2d[:, 2].max():.2f} (|z| > 0.1)")
            x_valid = ((points_2d[:, 0] > 0.0) & (points_2d[:, 0] < image_w)).sum()
            y_valid = ((points_2d[:, 1] > 0.0) & (points_2d[:, 1] < image_h)).sum()
            z_valid = (np.abs(points_2d[:, 2]) > 0.1).sum()
            print(f"     x ìœ íš¨: {x_valid}/{len(points_2d)}")
            print(f"     y ìœ íš¨: {y_valid}/{len(points_2d)}")
            print(f"     z ìœ íš¨: {z_valid}/{len(points_2d)}")
            
            valid_points_2d = points_2d[points_in_canvas_mask]
            valid_points_3d = point_in_camera_coords.T[points_in_canvas_mask]
            
            print(f"   í™”ë©´ ë²”ìœ„ ë‚´ ìœ íš¨ í¬ì¸íŠ¸: {len(valid_points_2d)}ê°œ")
            
            if len(valid_points_2d) == 0:
                return [], []
            
            # ê±°ë¦¬ ê¸°ë°˜ ìƒ‰ìƒ ê³„ì‚°
            distances = np.sqrt(np.sum(valid_points_3d**2, axis=1))
            colors = self._calculate_lidar_colors(distances)
            
            return valid_points_2d.astype(int), colors
            
        except Exception as e:
            print(f"âš ï¸ Error projecting LiDAR to camera: {e}")
            return [], []
    
    def _calculate_lidar_colors(self, distances: np.ndarray) -> np.ndarray:
        """ê±°ë¦¬ ê¸°ë°˜ LiDAR í¬ì¸íŠ¸ ìƒ‰ìƒ ê³„ì‚°"""
        try:
            # ê±°ë¦¬ ë²”ìœ„ ì •ê·œí™” (0-50m)
            max_distance = 50.0
            normalized_distances = np.clip(distances / max_distance, 0, 1)
            
            # Viridis ì»¬ëŸ¬ë§µ ì‚¬ìš©
            viridis_colors = np.array([
                [0.267, 0.004, 0.329],  # ë³´ë¼
                [0.282, 0.140, 0.457],  # íŒŒë‘
                [0.253, 0.265, 0.529],  # ì²­ë¡
                [0.206, 0.371, 0.406],  # ë…¹ìƒ‰
                [0.163, 0.471, 0.558],  # ì—°ë…¹
                [0.127, 0.567, 0.551],  # í™©ë¡
                [0.134, 0.658, 0.517],  # ë…¸ë‘
                [0.266, 0.748, 0.440],  # ì£¼í™©
                [0.477, 0.821, 0.318],  # ë¹¨ê°•
                [0.741, 0.873, 0.149],  # ë°ì€ ë¹¨ê°•
                [0.993, 0.906, 0.144]   # í°ìƒ‰
            ])
            
            # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ ë³´ê°„
            color_indices = (normalized_distances * (len(viridis_colors) - 1)).astype(int)
            color_indices = np.clip(color_indices, 0, len(viridis_colors) - 1)
            
            colors = viridis_colors[color_indices] * 255
            return colors.astype(int)
            
        except Exception as e:
            print(f"âš ï¸ Error calculating LiDAR colors: {e}")
            return np.array([[255, 255, 255]] * len(distances))
    
    def update_semantic_lidar_data(self, semantic_lidar_data: List[Dict]) -> None:
        """Semantic LiDAR ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸ (ì‹œê°í™”ìš©)"""
        try:
            if not semantic_lidar_data:
                self.lidar_points_2d = []
                self.lidar_colors = []
                return
            
            # Semantic í•„í„°ë§ ì ìš©
            filtered_data = self.filter_semantic_lidar_data(semantic_lidar_data)
            
            if not filtered_data:
                self.lidar_points_2d = []
                self.lidar_colors = []
                return
            
            # LiDAR í¬ì¸íŠ¸ ì¶”ì¶œ (í•„í„°ë§ëœ ë°ì´í„°)
            lidar_points_3d = []
            lidar_semantic_tags = []
            for point in filtered_data:
                lidar_points_3d.append([point['x'], point['y'], point['z']])
                lidar_semantic_tags.append(point['semantic_id']) # semantic_id ì €ì¥
            
            lidar_points_3d = np.array(lidar_points_3d).T # (3, N)
            
            # 3D -> 2D íˆ¬ì˜ (ì¹´ë©”ë¼ ë³€í™˜ í–‰ë ¬ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            if hasattr(self, 'camera_transform') and hasattr(self, 'camera_intrinsic'):
                camera_transform = self.camera_transform
                camera_intrinsic = self.camera_intrinsic
            else:
                # ê¸°ë³¸ ì¹´ë©”ë¼ ì„¤ì • (1080x720 í•´ìƒë„)
                camera_intrinsic = np.array([
                    [1080, 0, 540],
                    [0, 1080, 360],
                    [0, 0, 1]
                ])
                camera_transform = np.eye(4)
            
            # 3D í¬ì¸íŠ¸ë¥¼ ë™ì°¨ ì¢Œí‘œë¡œ ë³€í™˜
            lidar_points_3d_hom = np.vstack((lidar_points_3d, np.ones((1, lidar_points_3d.shape[1]))))
            
            # ì¹´ë©”ë¼ ë³€í™˜ ì ìš© (4x4 í–‰ë ¬)
            camera_points_3d = np.linalg.inv(camera_transform) @ lidar_points_3d_hom
            
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì ìš© (3x3 í–‰ë ¬)
            lidar_points_2d_hom = camera_intrinsic @ camera_points_3d[:3, :]
            
            # ì •ê·œí™”
            depths = lidar_points_2d_hom[2, :]
            valid_indices = np.where(depths > 0)[0] # ê¹Šì´ê°€ ì–‘ìˆ˜ì¸ ìœ íš¨í•œ í¬ì¸íŠ¸ë§Œ
            
            self.lidar_points_2d = (lidar_points_2d_hom[:2, valid_indices] / depths[valid_indices]).T
            
            # í™”ë©´ ë²”ìœ„ ë‚´ì— ìˆëŠ” í¬ì¸íŠ¸ë§Œ í•„í„°ë§
            screen_width, screen_height = (1080, 720)  # ê¸°ë³¸ í™”ë©´ í¬ê¸°
            valid_screen_indices = np.where(
                (self.lidar_points_2d[:, 0] >= 0) & (self.lidar_points_2d[:, 0] < screen_width) &
                (self.lidar_points_2d[:, 1] >= 0) & (self.lidar_points_2d[:, 1] < screen_height)
            )[0]
            
            self.lidar_points_2d = self.lidar_points_2d[valid_screen_indices]
            
            # ìœ íš¨í•œ semantic_tagë§Œ ì €ì¥
            valid_semantic_tags = [lidar_semantic_tags[i] for i in valid_indices[valid_screen_indices]]
            
            # semantic_tagì— ë”°ë¼ ìƒ‰ìƒ ì§€ì •
            self.lidar_colors = [self._get_color_from_semantic_tag(tag) for tag in valid_semantic_tags]
            
        except Exception as e:
            print(f"âš ï¸ Error updating semantic LiDAR data: {e}")
            self.lidar_points_2d = []
            self.lidar_colors = []

    def update_visualization(self, semantic_lidar_data: List[Dict], 
                           lidar_transform, camera_transform, camera_intrinsic: np.ndarray) -> None:
        """Semantic LiDAR ë°ì´í„°ë¥¼ ì‹œê°í™”ìš©ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ì°¨ëŸ‰ê³¼ ë³´í–‰ìë§Œ, ì„±ëŠ¥ ìµœì í™”)"""
        try:
            if not semantic_lidar_data:
                self.lidar_points_2d = []
                self.lidar_colors = []
                return
            
            # í•„í„°ë§ ì ìš© (ì°¨ëŸ‰ê³¼ ë³´í–‰ìë§Œ)
            filtered_data = self.filter_semantic_lidar_data(semantic_lidar_data)
            
            if not filtered_data:
                self.lidar_points_2d = []
                self.lidar_colors = []
                return
            
            # ì „ì²´ LiDAR í¬ì¸íŠ¸ë¥¼ ì¼ê´„ íˆ¬ì˜ (ì„±ëŠ¥ ìµœì í™”)
            all_points = []
            
            for point in filtered_data:
                point_coords = [point['x'], point['y'], point['z']]
                all_points.append(point_coords)
            
            # ì „ì²´ í¬ì¸íŠ¸ ì¼ê´„ íˆ¬ì˜
            all_points_2d = []
            all_colors = []
            
            if all_points:
                points_2d, colors = self.project_lidar_to_camera(
                    all_points, lidar_transform, camera_transform, camera_intrinsic
                )
                all_points_2d.extend(points_2d)
                all_colors.extend(colors)
            
            # ê²°ê³¼ ì €ì¥
            self.lidar_points_2d = all_points_2d
            self.lidar_colors = all_colors
            
            print(f"ğŸ¯ LiDAR ì‹œê°í™”: ì „ì²´ {len(all_points)}ê°œ í¬ì¸íŠ¸ ì²˜ë¦¬")
            print(f"   ğŸ“ ì´ {len(all_points_2d)}ê°œ í¬ì¸íŠ¸ê°€ ì¹´ë©”ë¼ í™”ë©´ì— íˆ¬ì˜ë¨")
            
        except Exception as e:
            print(f"âš ï¸ Error updating LiDAR visualization: {e}")
    
    def _get_color_for_semantic_id(self, semantic_id: int) -> Tuple[int, int, int]:
        """Semantic IDì— ë”°ë¼ ìƒ‰ìƒ ë°˜í™˜"""
        # CARLA semantic segmentation IDì— ë”°ë¥¸ ìƒ‰ìƒ ë§¤í•‘
        color_map = {
            0: (0, 0, 0),        # Unlabeled - ê²€ì€ìƒ‰
            1: (70, 70, 70),     # Road - íšŒìƒ‰
            2: (190, 153, 153),  # Sidewalk - ì—°í•œ íšŒìƒ‰
            3: (250, 170, 30),   # Lane marking - ì£¼í™©ìƒ‰
            4: (220, 20, 60),    # Vehicle - ë¹¨ê°„ìƒ‰
            5: (255, 0, 0),      # Pedestrian - ì§„í•œ ë¹¨ê°„ìƒ‰
            6: (0, 0, 142),      # Traffic sign - íŒŒë€ìƒ‰
            7: (0, 0, 70),       # Traffic light - ì§„í•œ íŒŒë€ìƒ‰
            8: (0, 60, 100),     # Vegetation - ì²­ë¡ìƒ‰
            9: (0, 0, 90),       # Terrain - ì§„í•œ íŒŒë€ìƒ‰
            10: (0, 0, 110),     # Sky - íŒŒë€ìƒ‰
            11: (80, 80, 80),    # Pole - íšŒìƒ‰
            12: (0, 0, 230),     # Traffic sign - ë°ì€ íŒŒë€ìƒ‰
            13: (128, 64, 128),  # Building - ë³´ë¼ìƒ‰
            14: (244, 35, 232),  # Wall - ë¶„í™ìƒ‰
            15: (70, 70, 70),    # Fence - íšŒìƒ‰
            16: (190, 153, 153), # Ground - ì—°í•œ íšŒìƒ‰
            17: (102, 102, 156), # Bridge - ë³´ë¼ìƒ‰
            18: (220, 220, 0),   # Rail track - ë…¸ë€ìƒ‰
            19: (150, 100, 100), # Guard rail - ê°ˆìƒ‰
            20: (230, 150, 140), # Static - ì—°í•œ ê°ˆìƒ‰
            21: (70, 130, 180),  # Dynamic - í•˜ëŠ˜ìƒ‰
            22: (220, 20, 60),   # Water - ë¹¨ê°„ìƒ‰
            23: (255, 0, 0),     # Road line - ë¹¨ê°„ìƒ‰
            24: (0, 0, 0),       # Ground - ê²€ì€ìƒ‰
            25: (128, 64, 128),  # Ground - ë³´ë¼ìƒ‰
            26: (70, 70, 70),    # Ground - íšŒìƒ‰
            27: (190, 153, 153), # Ground - ì—°í•œ íšŒìƒ‰
            28: (102, 102, 156), # Ground - ë³´ë¼ìƒ‰
            29: (220, 220, 0),   # Ground - ë…¸ë€ìƒ‰
            30: (150, 100, 100), # Ground - ê°ˆìƒ‰
        }
        
        return color_map.get(semantic_id, (255, 255, 255))  # ê¸°ë³¸ê°’: í°ìƒ‰
    
    def draw_overlay(self, screen: pygame.Surface) -> None:
        """pygame í™”ë©´ì— LiDAR í¬ì¸íŠ¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (ì°¨ëŸ‰ê³¼ ë³´í–‰ìë§Œ, ì„±ëŠ¥ ìµœì í™”)"""
        try:
            if not self.show_lidar_overlay or len(self.lidar_points_2d) == 0:
                return
            
            # ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ í¬ì¸íŠ¸ ìˆ˜ ì œí•œ
            max_points = 1000
            if len(self.lidar_points_2d) > max_points:
                # ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ í¬ì¸íŠ¸ ìˆ˜ ì œí•œ
                import random
                indices = random.sample(range(len(self.lidar_points_2d)), max_points)
                points_to_draw = [self.lidar_points_2d[i] for i in indices]
                colors_to_draw = [self.lidar_colors[i] for i in indices]
            else:
                points_to_draw = self.lidar_points_2d
                colors_to_draw = self.lidar_colors
            
            # LiDAR í¬ì¸íŠ¸ë“¤ì„ ì ìœ¼ë¡œ ê·¸ë¦¬ê¸°
            for point, color in zip(points_to_draw, colors_to_draw):
                # í™”ë©´ ë²”ìœ„ ë‚´ì— ìˆëŠ” í¬ì¸íŠ¸ë§Œ ê·¸ë¦¬ê¸°
                x, y = int(point[0]), int(point[1])
                if 0 <= x < screen.get_width() and 0 <= y < screen.get_height():
                    # ì°¨ëŸ‰ì€ í¬ê²Œ, ë³´í–‰ìëŠ” ì‘ê²Œ
                    if color == (220, 20, 60):  # ì°¨ëŸ‰ (ë¹¨ê°„ìƒ‰)
                        point_size = 3
                    else:  # ë³´í–‰ì (íŒŒë€ìƒ‰)
                        point_size = 2
                    
                    pygame.draw.circle(screen, color, (x, y), point_size)
            
        except Exception as e:
            print(f"âš ï¸ Error drawing LiDAR overlay: {e}")
    
    def toggle_overlay(self) -> None:
        """LiDAR ì˜¤ë²„ë ˆì´ í‘œì‹œ í† ê¸€"""
        self.show_lidar_overlay = not self.show_lidar_overlay
        print(f"ğŸ¯ LiDAR ì˜¤ë²„ë ˆì´: {'ON' if self.show_lidar_overlay else 'OFF'}")
    
    def get_class_name(self, semantic_id: int) -> str:
        """Semantic IDë¥¼ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        for class_name, class_id in self.target_semantic_classes.items():
            if class_id == semantic_id:
                return class_name
        return 'unknown'